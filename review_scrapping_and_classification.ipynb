{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный проект был выполнен в рамках обучения МФТИ.  \n",
    "\n",
    "От заказчика поступил размеченный датасет с отзывами о мобильных телефонах и тональности отзывов (положительный-отрицательный). Датасет маленький и содержит всего 100 строк. На таком датасете не возможно будет составить обучающую и тестовую выборку. Так же у заказчика требование - чтобы на тестовой выборке качество было не менее 80%.  \n",
    "  \n",
    "Выход в сложившейся ситуации - парсить отзывы с сайта такой же тематики.  \n",
    "\n",
    "Я нашёл сайт slonrekomenduet.com. На нём есть много отзывов о мобильных телефонах и смартфонах.  \n",
    "\n",
    "На сайте есть как отзывы, так и баллы. Скорее всего 4-5 баллов положительный отзыв, остальное - отрицательный.  \n",
    "Попробую пойти по следющему сценарию:\n",
    "\n",
    "1. Спарсить только отзывы всех телефонов и смартфонов.\n",
    "2. Обучить модель по вариану 1-3 балла neg, 4-5 pos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Баллы закодированы в звёздах, поэтому нужно будет считать активные звёзды как балл.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#парсинг страницы производителей\n",
    "def get_prods(url):\n",
    "    #получить все теги 'a' списка 'ul'\n",
    "    req = requests.get(url)\n",
    "    parser = bs4.BeautifulSoup(req.text, 'lxml')\n",
    "    parser = parser.find('ul')\n",
    "    prod_urls = parser.findAll('a', href=True)\n",
    "    #добавить их в массив\n",
    "    prods=[]\n",
    "    for prod in prod_urls:\n",
    "        prods.append('https://slonrekomenduet.com'+prod['href'])\n",
    "        \n",
    "    return prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#парсинг страницы моделей\n",
    "def get_models(url):\n",
    "    #найти на странице paginator\n",
    "    req = requests.get(url)\n",
    "    parser = bs4.BeautifulSoup(req.text, 'lxml')\n",
    "    parser = parser.find('div', attrs={'id':'paginator'})\n",
    "    page_urls = parser.findAll('a', href=True)\n",
    "    #если есть url других страниц, то добавить их в массив url\n",
    "    pages=[url]\n",
    "    if len(page_urls)>0:\n",
    "        for page in page_urls:\n",
    "            pages.append('https://slonrekomenduet.com'+page['href'])\n",
    "    \n",
    "    model_urls=[]\n",
    "    for page_model in pages:\n",
    "        req = requests.get(page_model)\n",
    "        parser = bs4.BeautifulSoup(req.text, 'lxml')\n",
    "        parser = parser.find('div', attrs={'id':'models'})\n",
    "        containers = parser.findAll('div', attrs={'class':'model'})\n",
    "        #добавить их в массив\n",
    "        for con in containers:\n",
    "            model=con.find('a', href=True)\n",
    "            model_urls.append('https://slonrekomenduet.com'+model['href'])\n",
    "    return model_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#получить баллы\n",
    "def get_stars(stars):\n",
    "    stars_count=[]\n",
    "    for x in stars:\n",
    "        stars_count.append(str(x).count('br-active'))\n",
    "    return stars_count\n",
    "\n",
    "#получить текст\n",
    "def get_text(text):\n",
    "    rev_text=[]\n",
    "    for x in text:\n",
    "        text=x.text\n",
    "        text=text.replace('Достоинства','Достоинства ')\n",
    "        text=text.replace('Недостатки','Недостатки ')\n",
    "        text=text.replace('Комментарий','Комментарий ')\n",
    "        rev_text.append(text)\n",
    "    return rev_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#парсинг страницы отзывов\n",
    "def get_rews(url):\n",
    "    #получить страницу отзывов, найти на ней пагинацию и спарсить все сраницы отзывов модели\n",
    "    #найти на странице paginator\n",
    "    req = requests.get(url)\n",
    "    parser = bs4.BeautifulSoup(req.text, 'lxml')\n",
    "    parser = parser.find('div', attrs={'id':'paginator'})\n",
    "    #если есть url других страниц, то добавить их в массив url\n",
    "    pages=[url]\n",
    "    if parser:\n",
    "        page_urls = parser.findAll('a', href=True)\n",
    "        for page in page_urls:\n",
    "            pages.append('https://slonrekomenduet.com'+page['href'])\n",
    "    \n",
    "    rev_stars=[]\n",
    "    rev_text=[]\n",
    "    for page_rew in pages:\n",
    "        req = requests.get(page_rew)\n",
    "        parser = bs4.BeautifulSoup(req.text, 'lxml')\n",
    "        parser = parser.find('div', attrs={'id':'user_reviews'})\n",
    "        review_meta = parser.findAll('div', attrs={'class':'br-theme-css-stars'})\n",
    "        review_text = parser.findAll('div', attrs={'class':'comment_text'})\n",
    "        stars=get_stars(review_meta)\n",
    "        text=get_text(review_text)\n",
    "        if len(stars)==len(text):\n",
    "            rev_stars.extend(stars)\n",
    "            rev_text.extend(text)\n",
    "    return rev_stars,rev_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get prods 112\n",
      "get models 2185\n",
      "get rews fiished: 187077\n"
     ]
    }
   ],
   "source": [
    "#массив баллов\n",
    "rev_stars=[]\n",
    "#массив отзывов\n",
    "rev_text=[]\n",
    "#массив страниц разделов\n",
    "pages_cat=[\n",
    "    'https://slonrekomenduet.com/category/phones.html',\n",
    "    'https://slonrekomenduet.com/category/smartphones.html'\n",
    "]\n",
    "#массив страниц производителей\n",
    "pages_prods=[]\n",
    "#массив страниц моделей\n",
    "pages_models=[]\n",
    "\n",
    "#получаю всех производителей\n",
    "for page_cat in pages_cat:\n",
    "    pages_prods.extend(get_prods(page_cat))\n",
    "    \n",
    "print('get prods',len(pages_prods))\n",
    "\n",
    "#получаю все модели\n",
    "for page_prod in pages_prods:\n",
    "    pages_models.extend(get_models(page_prod))\n",
    "    \n",
    "print('get models',len(pages_models))\n",
    "\n",
    "#получаю все отзывы\n",
    "for page_model in pages_models:\n",
    "    stars,text=get_rews(page_model)\n",
    "    rev_stars.extend(stars)\n",
    "    rev_text.extend(text)\n",
    "\n",
    "print('get rews fiished:',len(rev_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187077"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rev_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187077"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rev_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я получил 187077 отзывов о телефонах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'text': rev_text, 'stars': rev_stars}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>На белой коробке-упаковочке смешное фото: то-л...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хороший телефон .Соотношение цены и качества-о...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Достоинства : \\rподдержка карты памяти до 32 G...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Упаковка от телефона не очень понравилась, а и...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Достоинства : Первый день пользования. Ощущени...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  На белой коробке-упаковочке смешное фото: то-л...      1\n",
       "1  Хороший телефон .Соотношение цены и качества-о...      5\n",
       "2  Достоинства : \\rподдержка карты памяти до 32 G...      4\n",
       "3  Упаковка от телефона не очень понравилась, а и...      5\n",
       "4  Достоинства : Первый день пользования. Ощущени...      4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо удалить символ перевода строки _\"\\r\"_, а так же перевести баллы в показатель 0 и 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text=df.text.str.replace('\\r', ' ', regex=True)\n",
    "df.loc[df.stars>3,'class']=1\n",
    "df.loc[df.stars<=3,'class']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>На белой коробке-упаковочке смешное фото: то-л...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хороший телефон .Соотношение цены и качества-о...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Достоинства :  поддержка карты памяти до 32 Gb...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Упаковка от телефона не очень понравилась, а и...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Достоинства : Первый день пользования. Ощущени...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars  class\n",
       "0  На белой коробке-упаковочке смешное фото: то-л...      1    0.0\n",
       "1  Хороший телефон .Соотношение цены и качества-о...      5    1.0\n",
       "2  Достоинства :  поддержка карты памяти до 32 Gb...      4    1.0\n",
       "3  Упаковка от телефона не очень понравилась, а и...      5    1.0\n",
       "4  Достоинства : Первый день пользования. Ощущени...      4    1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    142441\n",
       "0.0     44636\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составлю датасет для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.text\n",
    "y=df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраню данные на всякий случай."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('rew_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('rew_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно попробовать различные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я хочу попробовать LinearSVC и LogisticRegression, так как по моему опыту они наиболее эффективны при работе с текстом.  \n",
    "Параметры одинаковые: n-gramm = 2 и лемматизатор pymystem3 с русскоязычной поддержкой. Векторизатор текста я использую TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/kirill/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "mystem = Mystem() \n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "def preprocess_text(X):\n",
    "    prep_text=[]\n",
    "    for text in X:\n",
    "        tokens = mystem.lemmatize(text.lower())\n",
    "        tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "                  and token != \" \" \\\n",
    "                  and token.strip() not in punctuation]\n",
    "    \n",
    "        text = \" \".join(tokens)\n",
    "    \n",
    "        prep_text.append(text)\n",
    "    return prep_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfdf_svc mean: 0.896438519537301\n",
      "tfdf_svc std: 0.007574252773938955\n",
      "tfdf_log mean: 0.8920926266556084\n",
      "tfdf_log std: 0.004048556700167318\n",
      "CPU times: user 10.6 s, sys: 7.1 s, total: 17.7 s\n",
      "Wall time: 2h 27min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfdf_svc_clf = Pipeline([('norm',FunctionTransformer(preprocess_text,validate = False)),\n",
    "                    ('vect', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "                     ('clf', LinearSVC())])\n",
    "\n",
    "tfdf_log_clf = Pipeline([('norm',FunctionTransformer(preprocess_text,validate = False)),\n",
    "                        ('vect', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "                         ('clf', LogisticRegression())])\n",
    "\n",
    "tfdf_svc_res=cross_val_score(tfdf_svc_clf,X,y,cv=5,scoring='accuracy',n_jobs=2)\n",
    "\n",
    "print(\"tfdf_svc mean:\",np.mean(tfdf_svc_res))\n",
    "print(\"tfdf_svc std:\",np.std(tfdf_svc_res))\n",
    "\n",
    "tfdf_log_res=cross_val_score(tfdf_log_clf,X,y,cv=5,scoring='accuracy',n_jobs=2)\n",
    "\n",
    "print(\"tfdf_log mean:\",np.mean(tfdf_log_res))\n",
    "print(\"tfdf_log std:\",np.std(tfdf_log_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Неплохо, теперь обучу модель на полных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('norm', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function preprocess_text at 0x7f1ab32f4b70>,\n",
       "          inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "          pass_y='deprecated', validate=False)), ('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='st...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfdf_log_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9316057024647605"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfdf_log_clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('norm', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function preprocess_text at 0x7f1ab32f4b70>,\n",
       "          inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "          pass_y='deprecated', validate=False)), ('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='st...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfdf_svc_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.997893915339673"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfdf_svc_clf.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скорее всего я выберу SVC  \n",
    "Теперь прочитаю данные из файла и сделаю по ним прогноз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "fileObj = codecs.open(\"test.csv\", \"r\", \"utf_8_sig\" )\n",
    "parser = bs4.BeautifulSoup(fileObj.read(), 'html.parser')\n",
    "review_meta = parser.findAll('review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text=[]\n",
    "for x in review_meta:\n",
    "    test_text.append(x.text.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=tfdf_svc_clf.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.y=res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.loc[sub.y==0,'y']='neg'\n",
    "sub.loc[sub.y==1,'y']='pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('result_svc.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=tfdf_log_clf.predict(test_text)\n",
    "sub.y=res\n",
    "sub.loc[sub.y==0,'y']='neg'\n",
    "sub.loc[sub.y==1,'y']='pos'\n",
    "sub.to_csv('result_log.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На kaggle https://www.kaggle.com/c/product-reviews-sentiment-analysis/submissions получилась точность валидации для svc 98%, для логистической регресии 96%, в итоге я превзошёл требования заказчика по точности классификации на 18%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
